{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "377469d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rapidfuzz\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import XSD, RDFS, RDF, OWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8dcaa04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    \"Peraturan Daerah Provinsi\": \"Perprov\",\n",
    "    \"Peraturan Wali Kota\": \"Perwali\",\n",
    "    \"Peraturan Bupati\": \"Perbup\",\n",
    "    \"Peraturan Kabupaten\": \"Perkab\",\n",
    "    \"Peraturan Kota\": \"Perkot\",\n",
    "    \"Peraturan Menteri Koordinator Bidang\": \"Permenko\",\n",
    "    \"Keputusan Menteri\": \"Kepmen\",\n",
    "    \"Peraturan Menteri\": \"Permen\",\n",
    "    \"Peraturan Bersama\": \"PB\",\n",
    "    \"Peraturan Presiden\": \"Perpres\",\n",
    "    \"Peraturan Daerah\": \"Perda\",\n",
    "    \"Peraturan Pemerintah\": \"PP\",\n",
    "    \"Undang-Undang Dasar\": \"UUD\",\n",
    "    \"Undang-Undang\": \"UU\",\n",
    "    \"Ketetapan Presiden\": \"Tapres\",\n",
    "    \"Keputusan Presiden\": \"Keppres\",\n",
    "    # permenko\n",
    "    \"Politik, Hukum, Dan Keamanan\": \"Polhukam\",\n",
    "    \"Perekonomian\": \"Perekonomian\",\n",
    "    \"Kesejahteraan Rakyat\": \"Kesra\",\n",
    "    \"Kemaritiman\": \"Maritim\",\n",
    "    \"Pembangunan Manusia Dan Kebudayaan\": \"PMK\",\n",
    "    # kepmen, permen, pb\n",
    "    \"Agama\": \"Agama\",\n",
    "    \"Kelautan Dan Perikanan\": \"KP\",\n",
    "    \"Kehutanan\": \"Hut\",\n",
    "    \"Lingkungan Hidup Dan Kehutanan\": \"LHK\",\n",
    "    \"Badan Usaha Milik Negara\": \"BUMN\",\n",
    "    \"Perencanaan Pembangunan Nasional/ Kepala Badan Perencanaan Pembangunan Nasional\": \"Bappenas\",\n",
    "    \"Perhubungan\": \"Hub\",\n",
    "    \"Pendayagunaan Aparatur Negara Dan Reformasi Birokrasi\": \"PANRB\",\n",
    "    \"Pertanian\": \"Tan\",\n",
    "    \"Energi Dan Sumber Daya Mineral\": \"ESDM\",\n",
    "    \"Riset, Teknologi, Dan Pendidikan Tinggi\": \"Ristekdikti\",\n",
    "    \"Riset Dan Teknologi\": \"Ristek\",\n",
    "    \"Pemuda Dan Olahraga\": \"Pora\",\n",
    "    \"Keuangan\": \"Keu\",\n",
    "    \"Pariwisata\": \"Par\",\n",
    "    \"Pertahanan\": \"Han\",\n",
    "    \"Kebudayaan Dan Pariwisata\": \"Budpar\",\n",
    "    \"Desa, Pembangunan Daerah Tertinggal, Dan Transmigrasi\": \"Desa\",\n",
    "    \"Perdagangan\": \"Dag\",\n",
    "    \"Riset Teknologi Dan Pendidikan Tinggi\": \"Ristekdikti\",\n",
    "    \"Agraria Dan Tata Ruang/ Kepala Badan Pertanahan Nasional\": \"ATRBPN\",\n",
    "    \"Pekerjaan Umum Dan Perumahan Rakyat\": \"PUPR\",\n",
    "    \"Pekerjaan Umum\": \"PU\",\n",
    "    \"Pendidikan Dan Kebudayaan\": \"Dikbud\",\n",
    "    \"Kesehatan\": \"Kes\",\n",
    "    \"Perindustrian\": \"Perin\",\n",
    "    \"Tenaga Kerja Dan Transmigrasi\": \"Nakertrans\",\n",
    "    \"Pariwisata Dan Ekonomi Kreatif\": \"Parekraf\",\n",
    "    \"Pembangunan Daerah Tertinggal\": \"PDT\",\n",
    "    \"Hukum Dan Hak Asasi Manusia\": \"Humham\",\n",
    "    \"Perumahan Rakyat\": \"PR\",\n",
    "    \"Pendidikan Nasional\": \"Dik\",\n",
    "    \"Dalam Negeri\": \"Dagri\",\n",
    "    \"Komunikasi Dan Informatika\": \"Kominfo\",\n",
    "    \"Sosial\": \"Sos\",\n",
    "    \"Koperasi Dan Usaha Kecil Dan Menengah\": \"Kopukm\",\n",
    "    \"Pemberdayaan Perempuan Dan Perlindungan Anak\": \"PPPA\",\n",
    "    \"Lingkungan Hidup\": \"LH\",\n",
    "    \"Luar Negeri\": \"LU\",\n",
    "    \"Sekretaris Negara\": \"Sesneg\",\n",
    "    \"Ketenagakerjaan\": \"Naker\",\n",
    "    \"Badan Pengawas Perdagangan Berjangka Komoditi\": \"Bappebti\",\n",
    "    \"Badan Pusat Statistik\": \"BPS\",\n",
    "    \"Lembaga Kebijakan Pengadaan Barang/jasa Pemerintah\": \"LKPP\",\n",
    "    \"Perpustakaan Nasional\": \"Perpusnas\",\n",
    "    \"Badan Tenaga Nuklir Nasional\": \"Batan\",\n",
    "    \"Komisi Nasional Hak Asasi Manusia\": \"Komnas HAM\",\n",
    "    \"Badan Narkotika Nasional\": \"BNN\",\n",
    "    \"Badan Pengawas Tenaga Nuklir\": \"Bapeten\",\n",
    "    \"Komisi Pengawas Persaingan Usaha\": \"KPPU\",\n",
    "    \"Komisi Informasi\": \"KI\",\n",
    "    \"Badan Nasional Penanggulangan Bencana\": \"BNPB\",\n",
    "    \"Pusat Pelaporan Dan Analisis Transaksi Keuangan\": \"PPATK\",\n",
    "    \"Lembaga Ilmu Pengetahuan Indonesia\": \"LIPI\",\n",
    "    \"Komisi Pemilihan Umum\": \"KPU\",\n",
    "    \"Badan Pengatur Hilir Minyak Dan Gas Bumi\": \"BPH Migas\",\n",
    "    \"Badan Pengelola Keuangan Haji\": \"BPKH\",\n",
    "    \"Badan Standardisasi Nasional\": \"BSN\",\n",
    "    \"Badan Meteorologi, Klimatologi, Dan Geofisika\": \"BMKG\",\n",
    "    \"Badan Nasional Penanggulangan Terorisme\": \"BNPT\",\n",
    "    \"Arsip Nasional\": \"ANRI\",\n",
    "    \"Lembaga Administrasi Negara\": \"LAN\",\n",
    "    \"Sekretaris Jenderal Ombudsman\": \"Ombudsman\",\n",
    "    \"Lembaga Perlindungan Saksi Dan Korban\": \"LPSK\",\n",
    "    \"Badan Wakaf Indonesia\": \"BWI\",\n",
    "    \"Dewan Perwakilan Daerah\": \"DPD\",\n",
    "    \"Lembaga Penjamin Simpanan\": \"LPS\",\n",
    "    \"Badan Pengkajian Dan Penerapan Teknologi\": \"BPPT\",\n",
    "    \"Badan Siber Dan Sandi Negara\": \"BSSN\",\n",
    "    \"Jaksa Agung\": \"Jagung\",\n",
    "    \"Badan Kependudukan Dan Keluarga Berencana Nasional\": \"BKKBN\",\n",
    "    \"Dewan Perwakilan Rakyat\": \"DPR\",\n",
    "    \"Badan Nasional Penempatan Dan Perlindungan Tenaga Kerja Indonesia\": \"BNP2TKI\",\n",
    "    \"Badan Pengawas Obat Dan Makanan\": \"BPOM\",\n",
    "    \"Badan Pengawas Pemilihan Umum\": \"Bawaslu\",\n",
    "    \"Komisi Aparatur Sipil Negara\": \"KASN\",\n",
    "    \"Badan Nasional Pencarian Dan Pertolongan\": \"Basarnas\",\n",
    "    \"Badan Kepegawaian Negara\": \"BKN\",\n",
    "    \"Dewan Jaminan Sosial Nasional\": \"DJSN\",\n",
    "    \"Badan Nasional Pengelola Perbatasan\": \"BNPP\",\n",
    "    \"Badan Keamanan Laut\": \"Bakamla\",\n",
    "    \"Badan Ekonomi Kreatif\": \"Bekraf\",\n",
    "    \"Badan Pengawasan Keuangan Dan Pembangunan\": \"BPKP\",\n",
    "    \"Kepala Kepolisian Negara\": \"Kapolri\",\n",
    "    \"Kepolisian Negara\": \"Polri\",\n",
    "    \"Komisi Pemberantasan Korupsi\": \"KPK\",\n",
    "    \"Mahkamah Agung\": \"MA\",\n",
    "    \"Badan Informasi Geospasial\": \"BIG\",\n",
    "    \"Konsil Kedokteran Indonesia\": \"KKI\",\n",
    "    \"Dewan Kawasan Perdagangan Bebas Dan Pelabuhan Bebas Batam\": \"PBBATAM\",\n",
    "    \"Lembaga Penerbangan Dan Antariksa Nasional\": \"Lapan\",\n",
    "    \"Sekretaris Kabinet\": \"Setkab\",\n",
    "    \"Badan Koordinasi Penanaman Modal\": \"BKPM\",\n",
    "    \"Otoritas Jasa Keuangan\": \"OJK\",\n",
    "    \"Badan Amil Zakat Nasional\": \"Baznas\",\n",
    "    \"Badan Pembinaan Ideologi Pancasila\": \"BPIP\",\n",
    "    \"Badan Penyelenggara Jaminan Sosial Kesehatan Reppublik Indonesia\": \"BPJSKES\",\n",
    "    \"Kepala Badan Pertanahan Nasional\": \"BPN\",\n",
    "    \"Bank Indonesia\": \"BI\",\n",
    "    \"Badan Pemeriksa Keuangan\": \"BPK\",\n",
    "    \"Komisi Yudisial\": \"KY\",\n",
    "    \"Dewan Kehormatan Penyelenggara Pemilihan Umum\": \"DKPP\",\n",
    "    \"Badan Penyelenggara Jaminan Sosial Ketenagakerjaan\": \"BPJSTK\",\n",
    "    \"Menteri\": \"Men\",\n",
    "    \"Ketua\": \"\",\n",
    "    \"Kepala\": \"\",\n",
    "    \"Kota\": \"\",\n",
    "    \"Kabupaten\": \"\",\n",
    "    \"Dan\": \"\",\n",
    "    # provinsi\n",
    "    \"Jawa Timur\": \"Jatim\",\n",
    "    \"Jawa Tengah\": \"Jateng\",\n",
    "    \"Irian Jaya Barat\": \"Irba\",\n",
    "    \"Jawa Barat\": \"Jabar\",\n",
    "    \"Nusa Tenggara Timur\": \"NTT\",\n",
    "    \"Sulawesi Utara\": \"Sulut\",\n",
    "    \"Daerah Istimewa Yogyakarta\": \"Yogya\",\n",
    "    \"Kalimantan Barat\": \"Kalbar\",\n",
    "    \"Sulawesi Barat\": \"Sulbar\",\n",
    "    \"Daerah Khusus Ibukota Jakarta\": \"DKI Jakarta\",\n",
    "    \"Kalimantan Tengah\": \"Kalteng\",\n",
    "    \"Kepulauan Riau\": \"Kep_Riau\",\n",
    "    \"Kalimantan Timur\": \"Kaltim\",\n",
    "    \"Sumatera Selatan\": \"Sumsel\",\n",
    "    \"Sumatera Barat\": \"Sumbar\",\n",
    "    \"Sulawesi Tengah\": \"Sulteng\",\n",
    "    \"Kalimantan Selatan\": \"Kalsel\",\n",
    "    \"Nusa Tenggara Barat\": \"NTB\",\n",
    "    \"Sumatera Utara\": \"Sumut\",\n",
    "    \"Sulawesi Selatan\": \"Sulsel\",\n",
    "    \"Kepulauan Bangka Belitung\": \"Kep Babel\",\n",
    "    \"Negara\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rel:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class LegalDocument:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "class LegalDocumentRef:\n",
    "    def __init__(self, name: str, label: str):\n",
    "        self.name = name\n",
    "        self.label = label\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Date:\n",
    "    def __init__(self, value: str):\n",
    "        self.value = value\n",
    "        \n",
    "class String:\n",
    "    def __init__(self, value: str):\n",
    "        self.value = value\n",
    "        \n",
    "class Int:\n",
    "    def __init__(self, value: str):\n",
    "        self.value = value\n",
    "\n",
    "class City:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Place:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "class Chapter:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Part:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "class Paragraph:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "class Extract:\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples\n",
    "\n",
    "class Triple:\n",
    "    def __init__(self, head, rel, tail):\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "        self.tail = tail\n",
    "\n",
    "class Extract:\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f785dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Men Hub --> Menhub; Men KP --> MENKP\n",
    "def convert_string(input_string):\n",
    "    pattern = r'(Men)\\s+(\\w+)'\n",
    "    replacement = lambda match: match.group(1).upper() + match.group(2) if match.group(2).isupper() else match.group(1) + match.group(2).lower()\n",
    "    output_string = re.sub(pattern, replacement, input_string).strip().replace(' ', '_')\n",
    "    return output_string\n",
    "\n",
    "# Mapping ke replacements\n",
    "def replace_similar(name, replacements, threshold=10):\n",
    "    for pattern, replacement in replacements.items():\n",
    "        name = name.replace('Republik Indonesia', '')\n",
    "        match = rapidfuzz.process.extractOne(name, [pattern], score_cutoff=threshold)\n",
    "        if match:\n",
    "            name = name.replace(match[0], replacement)\n",
    "    \n",
    "    def normalize(text):\n",
    "        return re.sub(r'[-\\s]+', ' ', text).strip()\n",
    "    \n",
    "    normalized_name = normalize(name)\n",
    "    \n",
    "    highest_ratio = 0\n",
    "    best_match = None\n",
    "    best_replacement = None\n",
    "    \n",
    "    for pattern, replacement in replacements.items():\n",
    "        normalized_pattern = normalize(pattern)\n",
    "        ratio = rapidfuzz.fuzz.QRatio(normalized_name, normalized_pattern)\n",
    "        if ratio > highest_ratio and ratio >= threshold:\n",
    "            highest_ratio = ratio\n",
    "            best_match = normalized_pattern\n",
    "            best_replacement = replacement\n",
    "    print(best_match)\n",
    "    print(best_replacement)\n",
    "    print(name)\n",
    "    \n",
    "    if best_match:\n",
    "        name = re.sub(r'\\b' + re.escape(best_match) + r'\\b', best_replacement, name, flags=re.IGNORECASE)\n",
    "    \n",
    "    return re.sub(r'\\s+', ' ', name.replace(',', ''))\n",
    "\n",
    "# Extract label peraturan sampai sebelum tentang --> [Nama Peraturan] Nomor [Nomor] Tahun [Tahun]\n",
    "def extract_regulation(input_text):\n",
    "    pattern_1 = r'(.*)(Nomor\\s+\\d+)\\s+(?:.*?)(Tahun\\s+\\d{4})'  # Nomor 29 Tahun 2000\n",
    "    pattern_2 = r'(.*)(Nomor\\s+\\d+)(?:\\/[^\\/]*?)*(\\/\\d{4})'  # Nomor 29/PP/2000\n",
    "    pattern_3 = r'(.*)(Nomor\\s+\\d+)(?:\\/[^\\/]*?)*(Tahun\\s+\\d+)'  # Nomor 29/PP Tahun 2000\n",
    "    pattern_4 = r'(Undang-Undang Dasar)(.*?)(Tahun\\s+\\d+)'\n",
    "    \n",
    "    match_1 = re.search(pattern_1, input_text)\n",
    "    match_2 = re.search(pattern_2, input_text)\n",
    "    match_3 = re.search(pattern_3, input_text)\n",
    "    match_4 = re.search(pattern_4, input_text)\n",
    "    \n",
    "    if match_1 or match_3:\n",
    "        match = match_1 if match_1 is not None else match_3\n",
    "        regulation_type = match.group(1)\n",
    "        number = match.group(2)\n",
    "        year = match.group(3)\n",
    "        res = f\"{regulation_type} {number} {year}\"\n",
    "        return re.sub(r'\\s+', ' ', res)\n",
    "    elif match_2:\n",
    "        regulation_type = match_2.group(1)\n",
    "        number = match_2.group(2)\n",
    "        year = \"Tahun \" + match_2.group(3)[1:]\n",
    "        res = f\"{regulation_type} {number} {year}\"\n",
    "        return re.sub(r'\\s+', ' ', res)\n",
    "    elif match_4:\n",
    "        regulation_type = match_4.group(1)\n",
    "        conj = match_4.group(2)\n",
    "        year = match_4.group(3)\n",
    "        res = f\"{regulation_type} {conj} {year}\"\n",
    "        return re.sub(r'\\s+', ' ', res)\n",
    "    else:\n",
    "        return input_text\n",
    "\n",
    "# [Nama Peraturan, Nomor XX Tahun YYYY]\n",
    "def split_regulation(text):\n",
    "    match = re.search(r'(.*?)(Nomor .*|Tahun .*)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        part1 = match.group(1).strip()\n",
    "        part2 = match.group(2).strip()\n",
    "        return [part1, part2]\n",
    "    else:\n",
    "        return [text, '']\n",
    "\n",
    "# Nomor XX Tahun YYYY --> YYYY_XX\n",
    "def convert_nomor_tahun(text):\n",
    "    match = re.search(r'Nomor (\\d+)\\s+Tahun (\\d+)', text, re.IGNORECASE)\n",
    "    match_2 = re.search(r'Tahun (\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        year = match.group(2)\n",
    "        return f\"{year}_{number}\"\n",
    "    elif match_2:\n",
    "        year = match_2.group(1)\n",
    "        return year\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Nama Peraturan --> id\n",
    "def convert_nama_peraturan(text):\n",
    "    converted_text = convert_string(replace_similar(text, replacements))\n",
    "    return converted_text\n",
    "\n",
    "\n",
    "def reg_to_id(text):\n",
    "    label = extract_regulation(text)\n",
    "    regulatory, num = split_regulation(label)\n",
    "    a = convert_nama_peraturan(regulatory)\n",
    "    b = convert_nomor_tahun(num)\n",
    "    reg_id = f'{a}_{b}' if b != '' else a\n",
    "    return label, reg_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a991d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    # BAB III\n",
    "    match = re.match(r'^BAB\\s+(\\w+)$', label)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Article 18\n",
    "    match = re.match(r'^Article\\s+(\\d+)$', label)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Bagian Kesatu BAB III\n",
    "    match = re.match(r'^Bagian\\s+(\\w+) BAB (\\w+)$', label)\n",
    "    if match:\n",
    "        return f\"{match.group(2)}_{match.group(1).upper()}\"\n",
    "    \n",
    "    # Paragraf 3 Bagian Kedua BAB III\n",
    "    match = re.match(r'^Paragraf\\s+(\\d+)\\s+Bagian\\s+(\\w+)\\s+BAB\\s+(\\w+)$', label)\n",
    "    if match:\n",
    "        return f\"{match.group(3)}_{match.group(2).upper()}_{match.group(1)}\"\n",
    "    \n",
    "    return label\n",
    "\n",
    "def parse_input_string(input_str):\n",
    "    input_str = input_str.replace('extract = ', '')\n",
    "    input_str = input_str.replace(',])', '')\n",
    "    \n",
    "    triples = []\n",
    "    pattern = re.compile(\n",
    "        r\"Triple\\((?P<head_type>\\w+)\\('(?P<head_value>.*?)'\\), \"\n",
    "        r\"Rel\\('(?P<rel>.*?)'\\), \"\n",
    "        r\"(?P<tail_type>\\w+)\\('(?P<tail_value>.*?)'\\)\\)\"\n",
    "    )\n",
    "    \n",
    "    for match in pattern.finditer(input_str):\n",
    "        head_type = match.group('head_type')\n",
    "        head_value = match.group('head_value')\n",
    "        rel = match.group('rel')\n",
    "        tail_type = match.group('tail_type')\n",
    "        tail_value = match.group('tail_value')\n",
    "        \n",
    "        if head_type in ('LegalDocument'):\n",
    "            label, name = reg_to_id(head_value)\n",
    "            head = LegalDocument(name)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if tail_type == 'Place':\n",
    "            tail = Place(tail_value)\n",
    "        elif tail_type == 'Date':\n",
    "            tail = Date(tail_value)\n",
    "        elif tail_type == 'String':\n",
    "            tail = String(tail_value)\n",
    "        elif tail_type == 'Int':\n",
    "            tail = Int(tail_value)\n",
    "        elif tail_type == 'City':\n",
    "            tail = City(tail_value)\n",
    "        elif tail_type == 'Person':\n",
    "            tail = Person(tail_value)\n",
    "        elif tail_type == 'Position':\n",
    "            tail = Position(tail_value)\n",
    "        elif tail_type == 'LegalDocument':\n",
    "            if ' ' not in tail_value:\n",
    "                tail = LegalDocument(tail_value)\n",
    "            else:\n",
    "                label, name = reg_to_id(tail_value)\n",
    "                tail = LegalDocumentRef(name, label)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        triples.append(Triple(head, Rel(rel), tail))\n",
    "    \n",
    "    return Extract(triples)\n",
    "\n",
    "def parse_input_string_2(input_str):\n",
    "    input_str = input_str.replace(\"\\n\", \"\").replace(\"    \", \"\").replace(\"extract = Extract([\", \"extract = Extract([\").replace(\"]))\", \")),])\")\n",
    "    input_str = input_str.replace('extract = ', '')\n",
    "    input_str = input_str.replace(',])', '')\n",
    "    \n",
    "    triples = []\n",
    "    pattern = re.compile(\n",
    "        r\"Triple\\((?P<head_type>\\w+)\\('(?P<head_value>.*?)'\\),\"\n",
    "        r\"Rel\\('(?P<rel>.*?)'\\),\"\n",
    "        r\"(?P<tail_type>\\w+)\\('(?P<tail_value>.*?)'\\)\\)\"\n",
    "    )\n",
    "    \n",
    "    for match in pattern.finditer(input_str):\n",
    "        head_type = match.group('head_type')\n",
    "        head_value = match.group('head_value')\n",
    "        rel = match.group('rel')\n",
    "        tail_type = match.group('tail_type')\n",
    "        tail_value = match.group('tail_value')\n",
    "        \n",
    "        if head_type in ('LegalDocument'):\n",
    "            label, name = reg_to_id(head_value)\n",
    "            head = LegalDocument(name)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if tail_type == 'Place':\n",
    "            tail = Place(tail_value)\n",
    "        elif tail_type == 'Date':\n",
    "            tail = Date(tail_value)\n",
    "        elif tail_type == 'String':\n",
    "            tail = String(tail_value)\n",
    "        elif tail_type == 'Int':\n",
    "            tail = Int(tail_value)\n",
    "        elif tail_type == 'City':\n",
    "            tail = City(tail_value)\n",
    "        elif tail_type == 'Person':\n",
    "            tail = Person(tail_value)\n",
    "        elif tail_type == 'Position':\n",
    "            tail = Position(tail_value)\n",
    "        elif tail_type == 'LegalDocument':\n",
    "            if ' ' not in tail_value:\n",
    "                tail = LegalDocument(tail_value)\n",
    "            else:\n",
    "                label, name = reg_to_id(tail_value)\n",
    "                tail = LegalDocumentRef(name, label)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        triples.append(Triple(head, Rel(rel), tail))\n",
    "    \n",
    "    return Extract(triples)\n",
    "\n",
    "def parse_input_string_3(input_str):\n",
    "    input_str = input_str.replace('extract = ', '')\n",
    "    input_str = input_str.replace(',])', '')\n",
    "    \n",
    "    triples = []\n",
    "    pattern = re.compile(\n",
    "        r\"Triple\\((?P<head_type>\\w+)\\('(?P<head_value>.*?)'\\), \"\n",
    "        r\"Rel\\('(?P<rel>.*?)'\\), \"\n",
    "        r\"(?P<tail_type>\\w+)\\('(?P<tail_value>.*?)'\\)\\)\"\n",
    "    )\n",
    "    \n",
    "    for match in pattern.finditer(input_str):\n",
    "        head_type = match.group('head_type')\n",
    "        head_value = match.group('head_value')\n",
    "        rel = match.group('rel')\n",
    "        tail_type = match.group('tail_type')\n",
    "        tail_value = match.group('tail_value')\n",
    "        \n",
    "        if head_type in 'LegalDocument':\n",
    "            head = LegalDocument(head_value)\n",
    "        elif head_type == 'Chapter':\n",
    "            head = Chapter(head_value)\n",
    "        elif head_type == 'Part':\n",
    "            head = Part(head_value)\n",
    "        elif head_type == 'Paragraph':\n",
    "            head = Paragraph(head_value)\n",
    "        elif head_type == 'Article':\n",
    "            head = Article(head_value)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if tail_type == 'Place':\n",
    "            tail = Place(tail_value)\n",
    "        elif tail_type == 'Date':\n",
    "            tail = Date(tail_value)\n",
    "        elif tail_type == 'String':\n",
    "            tail = String(tail_value)\n",
    "        elif tail_type == 'Int':\n",
    "            tail = Int(tail_value)\n",
    "        elif tail_type == 'City':\n",
    "            tail = City(tail_value)\n",
    "        elif tail_type == 'Person':\n",
    "            tail = Person(tail_value)\n",
    "        elif tail_type == 'Position':\n",
    "            tail = Position(tail_value)\n",
    "        elif tail_type == 'Chapter':\n",
    "            tail = Chapter(tail_value)\n",
    "        elif tail_type == 'Part':\n",
    "            tail = Part(tail_value)\n",
    "        elif tail_type == 'Paragraph':\n",
    "            tail = Paragraph(tail_value)\n",
    "        elif tail_type == 'Article':\n",
    "            tail = Article(tail_value)\n",
    "        elif tail_type == 'LegalDocument':\n",
    "            if ' ' not in tail_value:\n",
    "                tail = LegalDocument(tail_value)\n",
    "            else:\n",
    "                label, name = reg_to_id(tail_value)\n",
    "                tail = LegalDocumentRef(name, label)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        triples.append(Triple(head, Rel(rel), tail))\n",
    "    \n",
    "    return Extract(triples)\n",
    "\n",
    "\n",
    "def format_name(name):\n",
    "    name = re.sub(r'\\s+', '_', name)\n",
    "    name = name.replace(',', '').replace('.', '').replace('(', '').replace(')', '').title()\n",
    "    return name\n",
    "\n",
    "\n",
    "def format_name_body(label):\n",
    "    match = re.match(r'^(BAB|Bagian|Paragraf|Pasal)\\s+(\\w+)$', label)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    match = re.match(r'^(BAB|Bagian|Paragraf|Pasal)\\s+(\\d+)$', label)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    match = re.match(r'^Bagian\\s+(\\w+)\\s+BAB\\s+(\\w+)$', label)\n",
    "    if match:\n",
    "        return f\"{match.group(2)}_{match.group(1).upper()}\"\n",
    "    match = re.match(r'^Paragraf\\s+(\\d+)\\s+Bagian\\s+(\\w+)\\s+BAB\\s+(\\w+)$', label)\n",
    "    if match:\n",
    "        return f\"{match.group(3)}_{match.group(2).upper()}_{match.group(1)}\"\n",
    "    return format_name(label)\n",
    "\n",
    "\n",
    "def get_prefixed_name(reg, obj):\n",
    "    if isinstance(obj, City):\n",
    "        return f\"City_{format_name(obj.name)}\"\n",
    "    elif isinstance(obj, Person):\n",
    "        return f\"Person_{format_name(obj.name)}\"\n",
    "    elif isinstance(obj, Position):\n",
    "        return f\"Position_{format_name(obj.name)}\"\n",
    "    elif isinstance(obj, Chapter):\n",
    "        return f\"{reg}_Chapter_{format_name_body(obj.name)}\"\n",
    "    elif isinstance(obj, Part):\n",
    "        return f\"{reg}_Part_{format_name_body(obj.name)}\"\n",
    "    elif isinstance(obj, Paragraph):\n",
    "        return f\"{reg}_Paragraph_{format_name_body(obj.name)}\"\n",
    "    elif isinstance(obj, Article):\n",
    "        return f\"{reg}_Article_{format_name_body(obj.name)}\"\n",
    "    elif isinstance(obj, (LegalDocumentRef, LegalDocument)):\n",
    "        return f\"{(obj.name)}\"\n",
    "    return format_name(obj.name)\n",
    "\n",
    "\n",
    "def get_relation_name(name):\n",
    "    name = name.replace('hasName', 'name')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12634592",
   "metadata": {},
   "source": [
    "## RDF to TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "669f3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '''@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix wd: <https://www.wikidata.org/wiki/> .\n",
    "@prefix lexid-s: <https://w3id.org/lex-id/schema/> .\n",
    "@prefix lexid: <https://w3id.org/lex-id/data/> .\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "75397576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_triples(triple_str):\n",
    "    ttl = prefix\n",
    "    ttl += triple_str\n",
    "    \n",
    "    g = Graph()\n",
    "    DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "    DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "    WD = Namespace(\"https://www.wikidata.org/wiki/\")\n",
    "    LEXID_S = Namespace(\"https://w3id.org/lex-id/schema/\")\n",
    "    LEXID = Namespace(\"https://w3id.org/lex-id/data/\")\n",
    "\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"rdf\", RDF)\n",
    "    g.bind(\"dbo\", DBO)\n",
    "    g.bind(\"dct\", DCT)\n",
    "    g.bind(\"owl\", OWL)\n",
    "    g.bind(\"wd\", WD)\n",
    "    g.bind(\"lexid-s\", LEXID_S)\n",
    "    g.bind(\"lexid\", LEXID)\n",
    "    \n",
    "    try:\n",
    "        g.parse(data=ttl, format=\"turtle\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def is_valid_ttl(triple_str):\n",
    "    g = Graph()\n",
    "    DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "    DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "    WD = Namespace(\"https://www.wikidata.org/wiki/\")\n",
    "    LEXID_S = Namespace(\"https://w3id.org/lex-id/schema/\")\n",
    "    LEXID = Namespace(\"https://w3id.org/lex-id/data/\")\n",
    "\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"rdf\", RDF)\n",
    "    g.bind(\"dbo\", DBO)\n",
    "    g.bind(\"dct\", DCT)\n",
    "    g.bind(\"owl\", OWL)\n",
    "    g.bind(\"wd\", WD)\n",
    "    g.bind(\"lexid-s\", LEXID_S)\n",
    "    g.bind(\"lexid\", LEXID)\n",
    "    \n",
    "    try:\n",
    "        g.parse(data=triple_str, format=\"turtle\")\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f346db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pd.DataFrame()\n",
    "error = pd.DataFrame(columns=['regulatory', 'name', 'ttl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a2f19230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rdf(reg, name, cell):\n",
    "    ttl = prefix\n",
    "    \n",
    "    if not pd.isna(cell):\n",
    "        triples = cell.split('\\n')\n",
    "        \n",
    "        for j in range(len(triples)):\n",
    "            triple = triples[j]\n",
    "            \n",
    "            if is_valid_triples(triple):\n",
    "                ttl += triple + '\\n'\n",
    "                \n",
    "            if not is_valid_triples(triple) and triple.count(':') >= 3 and 'Name of' not in triple:\n",
    "                \n",
    "                #case triple kepisah line\n",
    "                if j + 1 < len(triples) and is_valid_triples(triples[j] + triples[j+1]):\n",
    "                    triple = triples[j] + triples[j+1]\n",
    "                \n",
    "                #case ada double \" contoh: lexid:Perkot_Denpasar_2006_1 lexid-s:hasEnactionDate \"\"2006-01-01\"\"^^xsd:date .\n",
    "                if '\"\"' in triple:\n",
    "                    triple = triple.replace('\"\"', '\"')\n",
    "                \n",
    "                #case enitity ada '\n",
    "                if \"'\" in triple:\n",
    "                    parts = re.split(r'(\".*?\")', triple)\n",
    "                    result = [part.replace(\"'\", \"\") if not part.startswith('\"') else part for part in parts]\n",
    "                    triple = ''.join(result)\n",
    "                \n",
    "                #case enitity ada /\n",
    "                if \"/\" in triple:\n",
    "                    parts = re.split(r'(\".*?\")', triple)\n",
    "                    result = [part.replace(\"/\", \"_\") if not part.startswith('\"') else part for part in parts]\n",
    "                    triple = ''.join(result)\n",
    "                \n",
    "                #case enitity ada /\n",
    "                if \"_&_\" in triple:\n",
    "                    parts = re.split(r'(\".*?\")', triple)\n",
    "                    result = [part.replace(\"_&_\", \"_dan_\") if not part.startswith('\"') else part for part in parts]\n",
    "                    triple = ''.join(result)\n",
    "                \n",
    "                # cek pattern ada spasi di antara entity setelah titik contoh: lexid:Person_R. Nuriyana\n",
    "                pattern1 = r'(\\. )(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)'\n",
    "                triple = re.sub(pattern1, '_', triple)\n",
    "                \n",
    "                #case: lexid:Position_Menteri_Kehakiman_a.i. rdfs:label \"Menteri Kehakiman a.i.\"^^xsd:string .\n",
    "                if '_rdf' in triple:\n",
    "                    triple = triple.replace('_rdf', ' rdf')\n",
    "                if \".\" in triple[:-1]:\n",
    "                    parts = re.split(r'(\".*?\")', triple[:-1])\n",
    "                    result = [part.replace(\".\", \"_\") if not part.startswith('\"') else part for part in parts]\n",
    "                    triple = ''.join(result) + '.'\n",
    "                \n",
    "                #case: lexid:Person_Sofyan_A_Dj LIABLE\n",
    "                index = triple.find(' rdf')\n",
    "                if index != -1:\n",
    "                    index_lexid = triple.find('lexid', 0, index)\n",
    "                    if index_lexid != -1:\n",
    "                        triple = triple[:index].replace(' ', '_') + triple[index:]\n",
    "\n",
    "                index_lexid_s = triple.find('lexid-s')\n",
    "                if index_lexid_s != -1:\n",
    "                    index_lexid = triple.find('lexid', index_lexid_s + len('lexid-s'))\n",
    "                    if index_lexid != -1:\n",
    "                        triple = triple[:index_lexid] + triple[index_lexid:].replace(' ', '_')\n",
    "                        \n",
    "                if 'Lexid' in triple:\n",
    "                    triple = triple.replace('Lexid', 'lexid')\n",
    "                    \n",
    "                # kurang titik\n",
    "                if triple[-1] != '.':\n",
    "                    triple += '.'\n",
    "                \n",
    "\n",
    "                if is_valid_triples(triple):\n",
    "                    ttl += triple + '\\n'\n",
    "                   \n",
    "    try:\n",
    "        if is_valid_ttl(ttl):\n",
    "            return ttl\n",
    "    except:\n",
    "        l = len(error)\n",
    "        error.at[l, 'regulatory'] = reg\n",
    "        error.at[l, 'name'] = name\n",
    "        error.at[l, 'ttl'] = cell\n",
    "        return prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b49498",
   "metadata": {},
   "source": [
    "## Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd387904",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_gemma = pd.read_csv('results/new/CC_gemma.csv')\n",
    "cc_llama = pd.read_csv('results/new/CC_llama.csv')\n",
    "cc_phi = pd.read_csv('results/new/CC_phi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_rdf(inp):\n",
    "    extract = parse_input_string(inp)\n",
    "    rdf_triples = []\n",
    "    res = ''\n",
    "\n",
    "    for triple in extract.triples:\n",
    "        head_lexid = f\"lexid:{get_prefixed_name(triple.head)}\"\n",
    "        rel_lexid = f\"lexid-s:{get_relation_name(triple.rel.name)}\"\n",
    "        \n",
    "        if rel_lexid == 'lexid-s:label':\n",
    "            rel_lexid = 'rdfs:label'\n",
    "\n",
    "        if isinstance(triple.tail, (LegalDocument, LegalDocumentRef, Place, City, Person, Position)):\n",
    "            tail_lexid = f\"lexid:{get_prefixed_name(triple.tail)}\"\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} {tail_lexid} .\")\n",
    "\n",
    "            if isinstance(triple.tail, City):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:City .\")\n",
    "            elif isinstance(triple.tail, Person):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Person .\")\n",
    "            elif isinstance(triple.tail, Position):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Position .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "            if isinstance(triple.tail, (City, Person, Position)):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.name}\\\"^^xsd:string .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} lexid-s:LegalBasisOf {head_lexid} .\")\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.label}\\\"^^xsd:string .\")\n",
    "\n",
    "        elif isinstance(triple.tail, Date):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:date .\")\n",
    "        elif isinstance(triple.tail, String):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:string .\")\n",
    "        elif isinstance(triple.tail, Int):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:int .\")\n",
    "            \n",
    "        if rel_lexid == 'lexid-s:regulationYear':\n",
    "            rdf_triples.append(f\"{head_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "    for triple in rdf_triples:\n",
    "        res += triple + '\\n'\n",
    "    \n",
    "    return res\n",
    "\n",
    "def rdf_to_ttl_1(name, filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    result = pd.DataFrame()\n",
    "    result = pd.DataFrame(columns=['regulatory', '1', '2', 'ttl_1', 'ttl_2'])\n",
    "    \n",
    "    target_filename = filename.replace('.csv', '_post.csv')\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        reg = df.at[i, 'regulatory']\n",
    "        out_1 = df.at[i, '1']\n",
    "        out_2 = df.at[i, '2']\n",
    "        \n",
    "        if pd.isna(out_1):\n",
    "            res_1 = ''\n",
    "        else:\n",
    "            res_1 = txt_to_rdf(out_1)\n",
    "            \n",
    "        if pd.isna(out_2):\n",
    "            res_2 = ''\n",
    "        else:\n",
    "            res_2 = txt_to_rdf(out_2)\n",
    "        \n",
    "        ttl_1 = check_rdf(reg, f'{name} 1', res_1)\n",
    "        ttl_2 = check_rdf(reg, f'{name} 2', res_2)\n",
    "            \n",
    "        result.at[i, 'regulatory'] = reg\n",
    "        result.at[i, '1'] = res_1\n",
    "        result.at[i, '2'] = res_2\n",
    "        result.at[i, 'ttl_1'] = ttl_1\n",
    "        result.at[i, 'ttl_2'] = ttl_2\n",
    "        \n",
    "        print(cnt, reg)\n",
    "        cnt += 1\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "            result.to_csv(target_filename)\n",
    "            \n",
    "    result.to_csv(target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_1('cc_gemma', 'results/new/CC_gemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605003df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_1('cc_llama', 'results/new/CC_llama.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_1('cc_phi', 'results/new/CC_phi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a68cb",
   "metadata": {},
   "source": [
    "## Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "20893597",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_gemma = pd.read_csv('results/new/OC_gemma.csv')\n",
    "oc_llama = pd.read_csv('results/new/OC_llama.csv')\n",
    "oc_phi = pd.read_csv('results/new/OC_phi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0fd495d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_label_gemma = pd.read_csv('results/new/OC_label_gemma.csv')\n",
    "oc_label_llama = pd.read_csv('results/new/OC_label_llama.csv')\n",
    "oc_label_phi = pd.read_csv('results/new/OC_label_phi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba45e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_rdf_2(reg, inp):\n",
    "    extract = parse_input_string_2(inp)\n",
    "    rdf_triples = []\n",
    "    res = ''\n",
    "    \n",
    "    for triple in extract.triples:\n",
    "        h = LegalDocument(reg)\n",
    "        head_lexid = f\"lexid:{get_prefixed_name(h)}\"\n",
    "        rel_lexid = f\"rdfs:{get_relation_name(triple.rel.name)}\"\n",
    "\n",
    "        if isinstance(triple.tail, (LegalDocument, LegalDocumentRef, Place, City, Person, Position)):\n",
    "            tail_lexid = f\"lexid:{get_prefixed_name(triple.tail)}\"\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} {tail_lexid} .\")\n",
    "\n",
    "            if isinstance(triple.tail, City):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:City .\")\n",
    "            elif isinstance(triple.tail, Person):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Person .\")\n",
    "            elif isinstance(triple.tail, Position):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Position .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "            if isinstance(triple.tail, (City, Person, Position)):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.name}\\\"^^xsd:string .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} lexid-s:LegalBasisOf {head_lexid} .\")\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.label}\\\"^^xsd:string .\")\n",
    "\n",
    "        elif isinstance(triple.tail, Date):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:date .\")\n",
    "        elif isinstance(triple.tail, String):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:string .\")\n",
    "        elif isinstance(triple.tail, Int):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:int .\")\n",
    "            \n",
    "        if rel_lexid == 'lexid-s:regulationYear':\n",
    "            rdf_triples.append(f\"{head_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "    for triple in rdf_triples:\n",
    "        res += triple + '\\n'\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_label_oc(reg, inp):\n",
    "    label = txt_to_rdf(inp)\n",
    "    if label == '':\n",
    "        label = txt_to_rdf_2(reg, inp)\n",
    "    return label.strip()\n",
    "\n",
    "def rdf_to_ttl_2(name, filename, file_label):\n",
    "    df = pd.read_csv(filename)\n",
    "    df_label = pd.read_csv(file_label)\n",
    "    result = pd.DataFrame()\n",
    "    result = pd.DataFrame(columns=['regulatory', '1', '2', 'ttl_1', 'ttl_2'])\n",
    "    \n",
    "    target_filename = filename.replace('.csv', '_post_0.csv')\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        reg = df.at[i, 'regulatory']\n",
    "        out_1_1 = df.at[i, '1_1']\n",
    "        out_1_2 = df.at[i, '1_2']\n",
    "        out_1_3 = df_label.at[i, '1_3']\n",
    "        out_2_1 = df.at[i, '2_1']\n",
    "        out_2_2 = df.at[i, '2_2']\n",
    "        out_2_3 = df_label.at[i, '2_3']\n",
    "        \n",
    "        if pd.isna(out_1_1):\n",
    "            res_1_1 = ''\n",
    "        else:\n",
    "            res_1_1 = txt_to_rdf(out_1_1)\n",
    "            \n",
    "        if pd.isna(out_1_2):\n",
    "            res_1_2 = ''\n",
    "        else:\n",
    "            res_1_2 = txt_to_rdf(out_1_2)\n",
    "            \n",
    "        if pd.isna(out_1_3):\n",
    "            res_1_3 = ''\n",
    "        else:\n",
    "            res_1_3 = get_label_oc(reg, out_1_3)\n",
    "            \n",
    "        if pd.isna(out_2_1):\n",
    "            res_2_1 = ''\n",
    "        else:\n",
    "            res_2_1 = txt_to_rdf(out_2_1)\n",
    "            \n",
    "        if pd.isna(out_2_2):\n",
    "            res_2_2 = ''\n",
    "        else:\n",
    "            res_2_2 = txt_to_rdf(out_2_2)\n",
    "            \n",
    "        if pd.isna(out_2_3):\n",
    "            res_2_3 = ''\n",
    "        else:\n",
    "            res_2_3 = get_label_oc(reg, out_2_3)\n",
    "            \n",
    "        res_1 = res_1_1 + res_1_2 + res_1_3\n",
    "        res_2 = res_2_1 + res_2_2 + res_2_3\n",
    "        \n",
    "        ttl_1 = check_rdf(reg, f'{name} 1', res_1)\n",
    "        ttl_2 = check_rdf(reg, f'{name} 2', res_2)\n",
    "            \n",
    "        result.at[i, 'regulatory'] = reg\n",
    "        result.at[i, '1'] = res_1\n",
    "        result.at[i, '2'] = res_2\n",
    "        result.at[i, 'ttl_1'] = ttl_1\n",
    "        result.at[i, 'ttl_2'] = ttl_2\n",
    "        \n",
    "        print(cnt, reg)\n",
    "        cnt += 1\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "            result.to_csv(target_filename)\n",
    "            \n",
    "    result.to_csv(target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48831ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdf_to_ttl_2('oc_gemma', 'results/new/OC_gemma.csv', 'results/new/OC_label_gemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715456eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_2('oc_llama', 'results/new/OC_llama.csv', 'results/new/OC_label_llama.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_2('oc_phi', 'results/new/OC_phi.csv', 'results/new/OC_label_phi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203f3e5",
   "metadata": {},
   "source": [
    "## Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bfc6287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_gemma = pd.read_csv('results/new/BC_gemma.csv')\n",
    "bc_llama = pd.read_csv('results/new/BC_llama.csv')\n",
    "bc_phi = pd.read_csv('results/new/BC_phi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39878c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_rdf_3(reg, inp):\n",
    "    extract = parse_input_string_3(inp)\n",
    "    rdf_triples = []\n",
    "    res = ''\n",
    "\n",
    "    for triple in extract.triples:\n",
    "        head_lexid = f\"lexid:{get_prefixed_name(reg, triple.head)}\"\n",
    "        rel_lexid = f\"lexid-s:{get_relation_name(triple.rel.name)}\"\n",
    "\n",
    "        if isinstance(triple.tail, (LegalDocument, LegalDocumentRef, Place, City, Person, Position, Chapter, Part, Paragraph, Article)):\n",
    "            tail_lexid = f\"lexid:{get_prefixed_name(reg, triple.tail)}\"\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} {tail_lexid} .\")\n",
    "\n",
    "            if isinstance(triple.tail, City):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:City .\")\n",
    "            elif isinstance(triple.tail, Person):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Person .\")\n",
    "            elif isinstance(triple.tail, Position):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:Position .\")\n",
    "            elif isinstance(triple.tail, Article):\n",
    "                rdf_triples.append(f\"{tail_lexid} lexid-s:name \\\"{triple.tail.name}\\\"^^xsd:string .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "            if isinstance(triple.tail, (City, Person, Position)):\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.name}\\\"^^xsd:string .\")\n",
    "            elif isinstance(triple.tail, LegalDocumentRef):\n",
    "                rdf_triples.append(f\"{tail_lexid} lexid-s:LegalBasisOf {head_lexid} .\")\n",
    "                rdf_triples.append(f\"{tail_lexid} rdfs:label \\\"{triple.tail.label}\\\"^^xsd:string .\")\n",
    "\n",
    "        elif isinstance(triple.tail, Date):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:date .\")\n",
    "        elif isinstance(triple.tail, String):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:string .\")\n",
    "        elif isinstance(triple.tail, Int):\n",
    "            rdf_triples.append(f\"{head_lexid} {rel_lexid} \\\"{triple.tail.value}\\\"^^xsd:int .\")\n",
    "            \n",
    "            \n",
    "        if rel_lexid == 'lexid-s:regulationYear':\n",
    "            rdf_triples.append(f\"{head_lexid} rdf:type lexid-s:LegalDocument .\")\n",
    "\n",
    "    for triple in rdf_triples:\n",
    "        res += triple + '\\n'\n",
    "    \n",
    "    return res\n",
    "\n",
    "def rdf_to_ttl_3(name, filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    result = pd.DataFrame()\n",
    "    result = pd.DataFrame(columns=['regulatory', '1', '2', 'ttl_1', 'ttl_2'])\n",
    "    \n",
    "    target_filename = filename.replace('.csv', '_fin_0.csv')\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        reg = df.at[i, 'regulatory']\n",
    "        out_1 = df.at[i, '1']\n",
    "        out_2 = df.at[i, '2']\n",
    "        \n",
    "        if pd.isna(out_1):\n",
    "            res_1 = ''\n",
    "        else:\n",
    "            res_1 = txt_to_rdf_3(reg, out_1)\n",
    "            \n",
    "        if pd.isna(out_2):\n",
    "            res_2 = ''\n",
    "        else:\n",
    "            res_2 = txt_to_rdf_3(reg, out_2)\n",
    "        \n",
    "        ttl_1 = check_rdf(reg, f'{name} 1', res_1)\n",
    "        ttl_2 = check_rdf(reg, f'{name} 2', res_2)\n",
    "            \n",
    "        result.at[i, 'regulatory'] = reg\n",
    "        result.at[i, '1'] = res_1\n",
    "        result.at[i, '2'] = res_2\n",
    "        result.at[i, 'ttl_1'] = ttl_1\n",
    "        result.at[i, 'ttl_2'] = ttl_2\n",
    "        \n",
    "        print(cnt, reg)\n",
    "        cnt += 1\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "            result.to_csv(target_filename)\n",
    "            \n",
    "    result.to_csv(target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_3('bc_gemma', 'results/new/BC_gemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_3('bc_llama', 'results/new/BC_llama.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_to_ttl_3('bc_phi', 'results/new/BC_phi.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
